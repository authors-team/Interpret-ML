<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>Authors</title>
    <link rel="stylesheet" type="text/css" href="css/style.css">
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
  </head>

  <body>

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
    <div class="container">
      <a class="navbar-brand" href="#">Interpret ML</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item active">
            <a class="nav-link" href="#">Section 01
              <span class="sr-only">(current)</span>
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="#">Section 02</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="#">Section 03</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="#">Section 04</a>
          </li>
          <li>
            <a class="btn btn-primary" href="#">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- Page Content -->
  <div class="container">

    <!-- Heading Row -->
    <div class="row align-items-center my-5">

      <div class="col-sm-12 col-lg-6 order-lg-1">
        <img class="img-fluid rounded mb-4 mb-lg-0" src="http://placehold.it/900x600" alt="">
      </div>

      <div class="col-sm-12 col-lg-6 order-lg-0">
        <h1>Understand Your Models</h1>
        <p>A toolkit for understanding and trusting models and modeling results that affect people's lives to explore questions like:</p>
        <div class="row">
          <div class="col-sm-6">
            <p>What drives model predictions?</p>
          </div>
          <div class="col-sm-6">
            <p>Why a model makes a certain decision?</p>
          </div>
          <div class="col-sm-6">
            <p>How changing features affect model predictions?</p>
          </div>
          <div class="col-sm-6">
            <p>How features interact to come up with model conclusions?</p>
          </div>
          <div class="col-sm-12">
            <p>What is the smallest change to the feature values that change the predictions to a predefined output?</p>
          </div>
        </div>
        <a class="btn btn-primary" href="#">Get Started</a>
        <a class="btn btn-primary" href="#">How It Works</a>
      </div>
    </div><!-- /.row -->
    
    <div class="row">
      <div class="col-sm-12 text-center">
        <h1>What is Interpretability in AI?</h1>
        <p>Gaining a comprehensive understanding of AI systems is a key requirement for data scientists, legal auditor, business decision makers, and providers of solutions to end users.</p><p>A bulk of state-of-the-art AI systems are still perceived as backbox difficult to decipher and understand. But businesses often ask questions such as “how can I trust your model?” or “Once deployed, is this model going to treat people fairly?”</p>
        <h1>Type of Interpretability</h1>
      </div>
    </div><!-- /.row -->

    <div class="row">
      <div class="col-md-4 mb-5">
        <div class="card h-100">
          <img class="card-img-top" src="http://placehold.it/300x200" alt="Card image cap">
          <div class="card-body">
            <h5 class="card-title">Glassbox</h5>
            <p class="card-text">Inherently interpretable. You're creating the model for that purpose. A linear model is an example. This model comes first, research partners care about this the most.</p>
          </div>
        </div>
      </div>
      <div class="col-md-4 mb-5">
        <div class="card h-100">
          <img class="card-img-top" src="http://placehold.it/300x200" alt="Card image cap">
          <div class="card-body">
            <h5 class="card-title">Blackbox</h5>
            <p class="card-text">I have a model, and I'm going to use the algorithms to explain its behavior.</p>
          </div>
        </div>
      </div>
      <div class="col-md-4 mb-5">
        <div class="card h-100">
          <img class="card-img-top" src="http://placehold.it/300x200" alt="Card image cap">
          <div class="card-body">
            <h5 class="card-title">Greybox</h5>
            <p class="card-text">Interpret any model in a specific family of models. An explainer forr neurel network models, I.e. It gives some knowledge of the particular class of models.</p>
          </div>
        </div>
      </div>
    </div><!-- /.row -->
    
    <div class="row">
      <div class="col-sm-12 text-center">
        <h1>When Should I Use InterpretML?</h1>
      </div>
      <div class="col-md-3 mb-5 text-center">
        <img class="img-fluid rounded mb-4 mb-lg-0" src="http://placehold.it/200x200" alt="">
        <h5>Researchers</h5>
        <p>You are a researcher and want to easily integrate your machine learning interpretability technique and compare it to other state-of-the-art interpretability techniques.</p>
      </div>
      <div class="col-md-3 mb-5 text-center">
        <img class="img-fluid rounded mb-4 mb-lg-0" src="http://placehold.it/200x200" alt="">
        <h5>Data Scientists / ML Developers</h5>
        <p>You are a data scientist/machine learning developer and want to achieve a comprehensive understanding of your model, perform error analysis to uncover potential issues, and explain your model to non-technical stakeholders.</p>
      </div>
      <div class="col-md-3 mb-5 text-center">
        <img class="img-fluid rounded mb-4 mb-lg-0" src="http://placehold.it/200x200" alt="">
        <h5>Legal Auditors</h5>
        <p>You are a business decision maker who wants to gain trust around machine learning models and make sure the model is not going to hurt the business or harm people.</p>
      </div>
      <div class="col-md-3 mb-5 text-center">
        <img class="img-fluid rounded mb-4 mb-lg-0" src="http://placehold.it/200x200" alt="">
        <h5>Business Decision Makers</h5>
        <p>You are a business decision maker who wants to gain trust around machine learning models and make sure the model is not going to hurt the business or harm people.</p>
      </div>
    </div><!-- /.row -->

    <div class="row">
      <div class="col-sm-12 text-center">
        <h1>InterpretML</h1>
        <p>InterpretML is a community-driven open source toolkit. Over the past few years, the machine learning interpretability landscape has been filled with techniques and open source packages. However, having to call different interpretability techniques from a set of very distinct repositories (each with a different API), and lack of unified visualizations to provide insights on model explanations have made the adoption of interpretability solutions slow and difficult.</p>
        <p>Our goal is to enable everyone to leverage state-of-the-art interpretability techniques using a unified set of API calls and visualizations.</p>
      </div>
    </div><!-- /.row -->

    <div class="row">
      <div class="col-sm-6">
        <h1>Easy Customization</h1>
        <p>Practitioners can easily experiment with the selection of glassbox models or greybox/blackbox explainers to find the technique that’s right for their application to generate model explanations. They can also choose interactive visualizations to perform what if analysis and perturbation scenarios, learning about model’s potential unfairness or error and issues.</p>
      </div>
      <div class="col-sm-6">
        <h1>Community Focus</h1>
        <p>InterpretML is designed to make it simple for the research community to add new interpretability techniques comparing it to the state-of-the-art techniques available in the toolkit.</p>
      </div>
    </div><!-- /.row -->


    <div class="row">
      <div class="col-sm-12 text-center">
        <h1>Generating Model Explanations</h1>
        <p>Automatically analyze predictions across different groups of people to identify potential harms of allocations or quality-of-service issues in your models.</p>
      </div>
      <div class="col-sm-6">
        <img class="img-fluid rounded mb-4 mb-lg-0" src="http://placehold.it/600x300" alt="">
      </div>
      <div class="col-sm-6 align-self-center">
        <h1>Global Feature Importance Values</h1>
        <p>Gain an understanding of entire model and what are the top factors affecting overall model predictions/comprehend the entire model by having a holistic view of feature importance values</p>
      </div>
      <div class="col-sm-6 align-self-center">
        <h1>Local Feature Importance Values</h1>
        <p>Explore a single prediction and see how its features have affected model prediction</p>
      </div>
      <div class="col-sm-6">
        <img class="img-fluid rounded mb-4 mb-lg-0" src="http://placehold.it/600x300" alt="">
      </div>
      <div class="col-sm-6">
        <img class="img-fluid rounded mb-4 mb-lg-0" src="http://placehold.it/600x300" alt="">
      </div>
      <div class="col-sm-6 align-self-center">
        <h1>Group Feature Importance Values</h1>
        <p>Explore a cohort/subset of data points (e.g., female) and observe how model has made predictions for that group.</p>
      </div>
      <div class="col-sm-12 text-center">
        <h1>Interactive Visualizations</h1>
        <p>Explore and easily explain findings with interactive visualizations</p>
      </div>
      <div class="col-sm-6 align-self-center">
        <p>Explore your data and model predictions</p>
        <p>Observe top global features and in what direction they impact predictions</p>
        <p>Observe top local features for a particular datapoint and in what direction they impact that single prediction</p>
      </div>
      <div class="col-sm-6">
        <img class="img-fluid rounded mb-4 mb-lg-0" src="http://placehold.it/600x300" alt="">
      </div>
      <div class="col-sm-6">
        <img class="img-fluid rounded mb-4 mb-lg-0" src="http://placehold.it/600x300" alt="">
      </div>
      <div class="col-sm-6 align-self-center">
        <p>Filter data to observe global and local features importance of a subset of data</p>
        <p>Run what-if analysis to explore how model predictions would change as you perturb one or multiple features</p>
      </div>
      <div class="col-sm-6 align-self-center">
        <h1>Explore Counterfactual Points</h1>
        <p>Explore the smallest change to the feature values that change the predictions to a predefined output</p>
      </div>
      <div class="col-sm-6">
        <img class="img-fluid rounded mb-4 mb-lg-0" src="http://placehold.it/600x300" alt="">
      </div>
    </div><!-- /.row -->

    <div class="row">
      <div class="col-sm-12 text-center">
        <h1>Start Understanding Your Model's Behavior</h1>
        <p>Lorem ipsum dolor sit amet, consectutur adipiscing elit. Sed pretium at est sit amet dictum.</p>
        <a class="btn btn-primary" href="#">Watch Tutorials</a>
        <a class="btn btn-primary" href="#">Github</a>
    </div><!-- /.row --> 

  </div><!-- /.container -->


  <!-- Footer -->
<div class="footer">
    <div class="spacer"></div>
    <div class="container d-flex justify-content-between py-4">
        <a class="navbar-brand" href="#">Interpret ML</a>
        <ul class="nav flex-column flex-sm-row">
            <li class="nav-item">
              <a class="nav-link" href="request-estimate.html">Section 01</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="our-work.html">Section 02</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="our-clients.html">Section 03</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="our-story.html">Section 04</a>
            </li>
            <li class="nav-item">
              <a class="btn btn-primary" href="#">Github</a>
            </li>
        </ul>
    </div>
    <div class="spacer"></div>
</div>


    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
  </body>
</html>